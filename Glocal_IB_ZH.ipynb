{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcd5eb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from Glocal_IB import Glocal_IB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35b1546e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. å®šä¹‰è¶…å‚æ•°\n",
    "BATCH_SIZE = 4\n",
    "SEQ_LEN = 24\n",
    "FEATURES = 10\n",
    "EMBEDDING_DIM = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyImputationModel(nn.Module):\n",
    "    \"\"\"ä¸€ä¸ªç®€å•çš„ä¼ªæ’è¡¥æ¨¡å‹\"\"\"\n",
    "    def __init__(self, seq_len, features, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.features = features\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.encoder = nn.Linear(features, embedding_dim)\n",
    "        self.decoder = nn.Linear(embedding_dim, features)\n",
    "        print(f\"åŸºç¡€æ¨¡å‹åˆå§‹åŒ–å®Œæ¯•ï¼Œè¾“å…¥ç‰¹å¾: {features}, åµŒå…¥ç»´åº¦: {embedding_dim}\")\n",
    "\n",
    "    def forward(self, x, **kwargs):\n",
    "        # è¾“å…¥ x ç»´åº¦: (batch, seq_len, features)\n",
    "        embedding = self.encoder(x)\n",
    "        \n",
    "        # è§£ç å™¨å°†åµŒå…¥å‘é‡æ‰©å±•å›åºåˆ—é•¿åº¦\n",
    "        # (batch, seq_len, embedding_dim)\n",
    "        reconstructed = embedding\n",
    "        output = self.decoder(reconstructed) # -> (batch, seq_len, features)\n",
    "\n",
    "        # æŒ‰ç…§çº¦å®šï¼Œè¿”å›æ’è¡¥ç»“æœå’Œä¸­é—´åµŒå…¥\n",
    "        return output, embedding\n",
    "    \n",
    "    def get_embedding_dim(self): # åªæ˜¯ä¸ºäº†æµ‹è¯• __getattr__ åŠŸèƒ½\n",
    "        return self.embedding_dim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5bb92a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "åŸºç¡€æ¨¡å‹åˆå§‹åŒ–å®Œæ¯•ï¼Œè¾“å…¥ç‰¹å¾: 10, åµŒå…¥ç»´åº¦: 64\n"
     ]
    }
   ],
   "source": [
    "# 2. å®ä¾‹åŒ–åŸºç¡€æ¨¡å‹å’Œ Glocal_IB åŒ…è£…å™¨\n",
    "base_model = DummyImputationModel(SEQ_LEN, FEATURES, EMBEDDING_DIM)\n",
    "\n",
    "# ä½¿ç”¨ \"cos_align\" ä½œä¸ºå¯¹é½æŸå¤±ï¼Œæƒé‡ä¸º 0.5\n",
    "glocal_model = Glocal_IB(\n",
    "    base_model=base_model, \n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    align_loss_type=\"cos_align\",\n",
    "    align_model_type=\"self\",\n",
    "    align_weight=0.5,\n",
    "    foundation_embedding=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90c455cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. å‡†å¤‡æ¨¡æ‹Ÿæ•°æ®\n",
    "x_complete = torch.randn(BATCH_SIZE, SEQ_LEN, FEATURES) # å®Œæ•´çš„åŸå§‹æ•°æ®\n",
    "x_masked = x_complete.clone()\n",
    "# éšæœºç”Ÿæˆä¸€ä¸ª maskï¼Œé®æ‰å¤§çº¦ 20% çš„æ•°æ®ç‚¹\n",
    "mask = torch.rand(x_masked.shape) > 0.8\n",
    "x_masked[mask] = 0 # å°†è¢«é®ç›–çš„æ•°æ®ç‚¹è®¾ä¸º0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2750f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ æ¨¡å¼: è®­ç»ƒ (Training)\n",
      "è¿”å›ç»“æœç±»å‹: <class 'dict'>\n",
      "å­—å…¸çš„é”®: dict_keys(['output', 'alignment_loss'])\n",
      "æ’è¡¥ç»“æœçš„å½¢çŠ¶: torch.Size([4, 24, 10])\n",
      "å¯¹é½æŸå¤±çš„å€¼: 0.4952\n",
      "é‡å»ºæŸå¤±: 1.0639\n",
      "æ€»æŸå¤± (ç”¨äºåå‘ä¼ æ’­): 1.5591\n"
     ]
    }
   ],
   "source": [
    "# 4. æ¨¡æ‹Ÿè®­ç»ƒè¿‡ç¨‹\n",
    "print(\"ğŸš€ æ¨¡å¼: è®­ç»ƒ (Training)\")\n",
    "glocal_model.train() # å°†æ¨¡å‹è®¾ç½®ä¸ºè®­ç»ƒæ¨¡å¼\n",
    "\n",
    "# åœ¨è®­ç»ƒæ—¶ï¼Œéœ€è¦åŒæ—¶ä¼ å…¥ masked å’Œ complete æ•°æ®\n",
    "training_results = glocal_model(x_masked, x_complete)\n",
    "\n",
    "print(f\"è¿”å›ç»“æœç±»å‹: {type(training_results)}\")\n",
    "print(f\"å­—å…¸çš„é”®: {training_results.keys()}\")\n",
    "\n",
    "# ä»å­—å…¸ä¸­è·å–æ’è¡¥ç»“æœå’Œå¯¹é½æŸå¤±\n",
    "imputation = training_results['output']\n",
    "alignment_loss = training_results['alignment_loss']\n",
    "\n",
    "print(f\"æ’è¡¥ç»“æœçš„å½¢çŠ¶: {imputation.shape}\")\n",
    "print(f\"å¯¹é½æŸå¤±çš„å€¼: {alignment_loss.item():.4f}\")\n",
    "\n",
    "# åœ¨å®é™…è®­ç»ƒä¸­ï¼Œä½ ä¼šè®¡ç®—ä¸€ä¸ªæ ‡å‡†çš„é‡å»ºæŸå¤±\n",
    "reconstruction_loss = F.mse_loss(imputation[~mask], x_complete[~mask])\n",
    "\n",
    "# æ€»æŸå¤±æ˜¯å¯¹é½æŸå¤±å’Œé‡å»ºæŸå¤±çš„åŠ æƒå’Œ\n",
    "total_loss = reconstruction_loss + alignment_loss\n",
    "print(f\"é‡å»ºæŸå¤±: {reconstruction_loss.item():.4f}\")\n",
    "print(f\"æ€»æŸå¤± (ç”¨äºåå‘ä¼ æ’­): {total_loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b4a9289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¬ æ¨¡å¼: è¯„ä¼° (Evaluation)\n",
      "è¿”å›ç»“æœç±»å‹: <class 'torch.Tensor'>\n",
      "æ’è¡¥ç»“æœçš„å½¢çŠ¶: torch.Size([4, 24, 10])\n"
     ]
    }
   ],
   "source": [
    "# 5. æ¨¡æ‹Ÿè¯„ä¼°/æ¨ç†è¿‡ç¨‹\n",
    "print(\"ğŸ”¬ æ¨¡å¼: è¯„ä¼° (Evaluation)\")\n",
    "glocal_model.eval() # å°†æ¨¡å‹è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼\n",
    "\n",
    "# åœ¨è¯„ä¼°æ—¶ï¼Œåªä¼ å…¥ masked æ•°æ®\n",
    "with torch.no_grad():\n",
    "    eval_output = glocal_model(x_masked)\n",
    "\n",
    "print(f\"è¿”å›ç»“æœç±»å‹: {type(eval_output)}\")\n",
    "print(f\"æ’è¡¥ç»“æœçš„å½¢çŠ¶: {eval_output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17f6bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ æ¼”ç¤º __getattr__ åŠŸèƒ½\n",
      "é€šè¿‡ Glocal_IB åŒ…è£…å™¨ç›´æ¥è°ƒç”¨åŸºç¡€æ¨¡å‹çš„æ–¹æ³•: glocal_model.get_embedding_dim() -> 64\n",
      "ä¸ç›´æ¥è°ƒç”¨åŸºç¡€æ¨¡å‹çš„ç»“æœä¸€è‡´: base_model.get_embedding_dim() -> 64\n"
     ]
    }
   ],
   "source": [
    "# 6. æ¼”ç¤º __getattr__ çš„ä½œç”¨\n",
    "print(\"ğŸ æ¼”ç¤º __getattr__ åŠŸèƒ½\")\n",
    "# å°½ç®¡æˆ‘ä»¬æ“ä½œçš„æ˜¯ glocal_modelï¼Œä½†å¯ä»¥åƒè°ƒç”¨ base_model çš„æ–¹æ³•ä¸€æ ·ç›´æ¥è°ƒç”¨\n",
    "# è¿™æ˜¯å› ä¸º __getattr__ ä¼šè‡ªåŠ¨å°†è°ƒç”¨è½¬å‘ç»™å†…éƒ¨çš„ self.base_model\n",
    "emb_dim = glocal_model.get_embedding_dim()\n",
    "print(f\"é€šè¿‡ Glocal_IB åŒ…è£…å™¨ç›´æ¥è°ƒç”¨åŸºç¡€æ¨¡å‹çš„æ–¹æ³•: glocal_model.get_embedding_dim() -> {emb_dim}\")\n",
    "print(f\"ä¸ç›´æ¥è°ƒç”¨åŸºç¡€æ¨¡å‹çš„ç»“æœä¸€è‡´: base_model.get_embedding_dim() -> {base_model.get_embedding_dim()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work4-v1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
